# Conclusion

## Summary 

Hot extremes present a threat to human health, the economy and sensitive ecosystems. Although the variability in yearly hot extreme magnitudes has been studied and regionally linked to various physical mechanisms, a global view on these events lacks. This thesis bridges this gap by exploring the spatial variability observed in the year-to-year variability of TX1day events and link it to the year-to-year variability in the contribution from advective, adiabatic and diabatic heat-generating mechanisms. By considering the Lagrangian approach proposed by \cite{rothlisberger_quantifying_2023}, its mean-state characterizations are extended to a comprehensive second-moment analysis.

Global patterns in TX1day $T'$ variance are found to be similar to TX1day $T'$ magnitudes, with predominantly larger variance over land and increasing with increasing latitude. There is however more defined land-ocean contrasts, particularly on the Western coasts of continents between 25$^\circ$ and 60$^{\circ}$ North and 15$^\circ$ and 60$^\circ$ South with up to 16$^\circ$C$^2$ differences in variance in just 100km. No physical process is found to dominate TX1day event variability and the processes dominating the mean exhibit again similar patterns to those in the variance. Only few local regions - including the high-variability Western coasts - have a single contributor dominating the variance and these generally agree with the mean behavior. However, dominance in the mean by a contributor does not imply dominance in the variance only by this contributor, with more complete contributions from all three processes globally. Most significantly, this analysis finds that diabatic $T'$ variance contributions are often large, despite negative contribution in the mean. This suggests that diabatic processes through diverse land-atmosphere feedbacks and cloud-cover are important in year-to-year variability of hot extremes. This supports existing literature \citep{wehrli_identifying_2019,miralles_mega-heatwave_2014,schumacher_amplification_2019}, although finding a larger influence in the mid- to high-latitudes than \cite{wehrli_extremex_2022}.

Furthermore, the large and mostly negative covariances in \@ref(fig:vardecomp) are examined through PCA, finding that most of the globe has the variability of the three contributors constrained to only one or two axes of variability. This implies that, particularly over oceans, complex mechanisms suggested by the variance decomposition and supported in the literature can be more simply characterized. In regions with variance that remains poorly explained by two axes, contributors then act more independently which may suggest the influence of a larger diversity of physical mechanisms along parcel trajectories. These areas are found in high latitudes, such as over Northern Russia and Canada, and further suggests that Arctic amplification \citep{cohen_recent_2014} may be responsible for this complexity. 

The approach for the analysis of parcel trajectories was limited due to poor predictive performance in many locations. Some tendencies were learned and thus out-performed the constant baseline everywhere except in tropical regions where small temperature anomalies were exaggerated by the model. We have however shown that the patterns in advective, adiabatic and diabatic temperature anomaly generation may be predicted from their history with a relative simple model, encouraging for future work. In addition, over oceans and many land regions we observe that adiabatic heating is minimal during the final 24h, suggesting that hot extreme primarily descend to the surface earlier than a day before, thus leading to contributions from advective and diabatic processes more likely.

## Limitations and future work

Although providing novel insights into the global variability of physical processes contributing to hot extreme development, the methods proposed have several limitations. First of all, the variance decomposition only explores the year-to-year variability of the cumulative total $T'$ contribution. A total estimate is meaningful, but it cannot easily make statements about the underlying dynamical structures. Nonetheless, together with PCA, these methods provide a unique perspective into the interactions involved in hot extreme development on a global scale.

This thesis was then largely successful in analyzing the patterns in the final cumulative trajectory data. However, many questions considering the timeseries history of TX1day event trajectories remain open. The approach to explore hot extreme dynamics with the use of DL for the modelling of final-day evolution was unsuccessful due to the model's poor performance. This work has however shown that some dependencies between contributors may be learned by even a simple model and that they are useful for forecasting next-day tendencies of each contributor. Given the large dataset considered and the diversity of timeseries behaviors, we suggest that future work should consider the following two changes. First, a revision of the data pre-processing: scaling by the median and inter-quantile range - although effective in dampening the influence of outlying values - did not transform each contributor to comparable ranges, which likely heavily biased the model to focus on limiting the loss due to the contributor with the largest scaled magnitude. Second, a more complex model may be required: this work focused on the contributors and therefore did not consider any additional trajectory information, such as geographical location and pressure level that are shown to play an important role. Given the large dataset, a sufficiently large neural network may learn to infer these features but to balance computational burden and model performance, these features may improve the ability of the model to capture changing dynamical mechanisms. In addition, increasing the number of LSTM hidden units may be required to obtain a richer feature-representation for each timeseries that can then be processed by the linear layer. 

Another limitation of the model is that it was trained to predict only the last 24h in each trajectory. Although the model makes use of the full trajectory history and therefore learns important patterns in the evolution of each physical mechanism, it limits inference for the final 24h period and forces it to output an average behavior when trajectories are younger than the forecasting window. As was seen, some trajectories show little evolution in the final 24h - either for a single or multiple contributors - and therefore may learn to ignore important aspects of the hot extreme development when outputting flat forecasts. Future work may then focus on training a model on diverse input windows - i.e. only using a set number of timesteps - to predict different sections of each trajectory. Exposing a model to different situations, rather than the complete history, would likely improve its ability to learn more meaningful dynamical patterns, thus improving predictive performance. Furthermore, prediction for various temporal regions would allow for a broader application of the model. 

Finally, the model did not allow 'opening the black-box' to more precisely explore the interactions between contributors and how they relate to model predictions. This requires a model that performs well on the test-data, both in terms of low MSE loss and its ability to correctly predict general trends. Given the improvements suggested above are successful in developing a better model, future work should focus on its interpretability. Explainable AI methods have received considerable attention recently and many frameworks have been extended for multivariate timeseries data. WindowSHAP \citep{nayebi_windowshap_2023} is a post-hoc method that assigns importance to windows of input multivariate timesteps. It is particularly attractive for this problem as it is computationally more efficient than other masking based methods \citep[see][for a review]{rojat_explainable_2021} and provides local explanations - for an individual samples. In the context of TX1day trajectory, it then allows the identification of important time intervals and their comparison between timeseries achieving low to high final temperature anomalies. Another approach, that further reduces computational burden, is the addition of an attention mechanism to the LSTM-model presented in this thesis. Attention-mechanisms introduce learnable parameters that are optimized to give more weight to timesteps that relate to the target, thus being more discriminating than the vanilla LSTM. They have, for example, been successful in flood forecasting applications \citep{ding_interpretable_2020}, where the attention weights can then be interpreted directly and compared between inputs. 
